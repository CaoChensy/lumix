{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-]","pipeline":["stemmer"]},"docs":[{"location":"","title":"Quick Start","text":"<p>\u200b\u5b89\u88c5\u200b</p> <pre><code>pip install lumix\n</code></pre> <p>\u200b\u57fa\u672c\u200b\u4f7f\u7528\u200b</p> \u200b\u5927\u200b\u6a21\u578b\u200bAPI\u200b\u8c03\u7528\u200b \u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200bOutput <pre><code>from lumix.llm import OpenAI\n\nbase_url = \"https://open.bigmodel.cn/api/paas/v4\"\nllm = OpenAI(model=\"glm-4-flash\", base_url=base_url, api_key=\"your_api_key\")\n\ncompletion = self.llm.completion(prompt=\"\u200b\u4f60\u597d\u200b\")\nprint(completion.choices[0].message.content)\n</code></pre> <pre><code>[User] \u200b\u4f60\u597d\u200b\n[Assistant] \u200b\u4f60\u597d\u200b\ud83d\udc4b\uff01\u200b\u5f88\u200b\u9ad8\u5174\u200b\u89c1\u5230\u200b\u4f60\u200b\uff0c\u200b\u6709\u200b\u4ec0\u4e48\u200b\u53ef\u4ee5\u200b\u5e2e\u52a9\u200b\u4f60\u200b\u7684\u200b\u5417\u200b\uff1f\n</code></pre>"},{"location":"agent/","title":"Agent","text":"Agent Search \u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200bOutput <pre><code>from lumix.llm import OpenAI\nfrom lumix.agent import ToolsAgent, Tools\nfrom lumix.agent.tools import baidu_search\nfrom lumix.types.messages import SystemMessage, UserMessage\n\nbase_url = \"https://api-inference.modelscope.cn/v1/\"\nmodel = \"Qwen/Qwen2.5-14B-Instruct-1M\"\nllm = OpenAI(model=model, base_url=base_url, key_name=\"MODELSCOPE_TOKEN\", verbose=False)\ntools = Tools(tools=[baidu_search])\nagent = ToolsAgent(tools=tools, llm=llm, verbose=True)\n\nmessages = [\n    SystemMessage(content=\"You are a helpful assistant. Use search tool before answer user's question. Answer in Markdown format and give the corresponding url quote.\"),\n    UserMessage(content=\"\u200b\u76ee\u524d\u200b\u56fd\u9645\u200b\u4e52\u4e53\u200b\u79ef\u5206\u200b\u6392\u540d\u200b\u524d\u4e94\u200b\u7684\u200b\u662f\u200b\u54ea\u4e9b\u200b\u4eba\u200b\uff0c\u200b\u79ef\u5206\u200b\u662f\u200b\u591a\u5c11\u200b\uff1f\")\n]\ncompletion = agent.completion(messages=messages)\nprint(completion.choices[0].message.content)\n</code></pre> <pre><code>\u200b\u6839\u636e\u200b\u6700\u65b0\u200b\u7684\u200b\u56fd\u9645\u200b\u4e52\u4e53\u7403\u200b\u8054\u5408\u4f1a\u200b\uff08WTT\uff09\u200b\u6392\u540d\u200b\uff0c\u200b\u4ee5\u4e0b\u200b\u662f\u200b\u7537\u5973\u200b\u5355\u6253\u200b\u6392\u540d\u200b\u524d\u4e94\u200b\u7684\u200b\u60c5\u51b5\u200b\uff1a\n\n### \u200b\u7537\u5b50\u5355\u6253\u200b\uff1a\n1. \u200b\u6797\u8bd7\u680b\u200b - 8025 \u200b\u5206\u200b\n2. \u200b\u738b\u695a\u200b\u94a6\u200b - 7925 \u200b\u5206\u200b\n3. \u200b\u6881\u9756\u200b\u5d11\u200b - 5425 \u200b\u5206\u200b\n4. \u200b\u5f20\u672c\u200b\u667a\u200b\u548c\u200b - 4950 \u200b\u5206\u200b\n5. \u200b\u9a6c\u9f99\u200b - 4850 \u200b\u5206\u200b\n\n### \u200b\u5973\u5b50\u5355\u6253\u200b\uff1a\n1. \u200b\u5b59\u9896\u838e\u200b - 11300 \u200b\u5206\u200b\n2. \u200b\u738b\u66fc\u6631\u200b - 8850 \u200b\u5206\u200b\n3. \u200b\u738b\u827a\u8fea\u200b - 5425 \u200b\u5206\u200b\n4. \u200b\u9648\u5e78\u200b\u540c\u200b - 4250 \u200b\u5206\u200b\n5. \u200b\u65e9\u7530\u5e0c\u5a1c\u200b - 4200 \u200b\u5206\u200b\n\n\u200b\u4ee5\u4e0a\u200b\u6570\u636e\u200b\u6765\u6e90\u4e8e\u200b[\u200b\u4e16\u754c\u200b\u4e52\u8054\u200b\u6700\u65b0\u200b\u6392\u540d\u200b](http://www.baidu.com/link?url=s8C6OqE8cFjCm09asXg5hNcgb4I1-jxnlk_cyyY3R_o9H3oirLenCJ3WPh2G76tYCRePLavp0IhnsKmW5rJIn5ByXntcmlg73kuNnqtlveO)\u3002\n</code></pre>"},{"location":"llm/","title":"LLM","text":""},{"location":"llm/#lumix.llm.completion.openai.OpenAI","title":"OpenAI","text":"<pre><code>OpenAI(\n    model: str,\n    base_url: Optional[str] = \"https://api.openai.com/v1\",\n    api_key: Optional[str] = None,\n    key_name: Optional[str] = None,\n    client: Optional[OpenAI] = None,\n    verbose: Optional[bool] = False,\n    logger: Optional[Union[Logger, Callable]] = None,\n    **kwargs: Any\n)\n</code></pre> <p>Initialize a new instance of OpenAI client.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The model to use for completion.</p> required <code>base_url</code> <code>Optional[str]</code> <p>The base URL of the API endpoint.</p> <code>'https://api.openai.com/v1'</code> <code>api_key</code> <code>Optional[str]</code> <p>The API key used for authentication.</p> <code>None</code> <code>key_name</code> <code>Optional[str]</code> <p>The name of the API key used for authentication. If not provided, the first API key in the environment variables will be used.</p> <code>None</code> <code>client</code> <code>Optional[OpenAI]</code> <p>The HTTP client instance used to make requests to the API. This could be an instance of a library like <code>requests</code> or a custom client implementation.</p> <code>None</code> <code>verbose</code> <code>Optional[bool]</code> <p>A boolean flag indicating whether to enable verbose output. When set to True, additional debugging information or logs will be displayed.</p> <code>False</code> <code>logger</code> <code>Optional[Union[Logger, Callable]]</code> <p>A logger instance used for logging messages.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Examples:     <pre><code>from lumix.llm import OpenAI\n\nbase_url = \"https://open.bigmodel.cn/api/paas/v4\"\nllm = OpenAI(model=\"glm-4-flash\", base_url=base_url, api_key=\"your_api_key\")\n</code></pre></p> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def __init__(\n        self,\n        model: str,\n        base_url: Optional[str] = \"https://api.openai.com/v1\",\n        api_key: Optional[str] = None,\n        key_name: Optional[str] = None,\n        client: Optional[OpenAIOriginal] = None,\n        verbose: Optional[bool] = False,\n        logger: Optional[Union[Logger, Callable]] = None,\n        **kwargs: Any,\n):\n    \"\"\" Initialize a new instance of OpenAI client.\n\n    Args:\n        model:\n            The model to use for completion.\n        base_url:\n            The base URL of the API endpoint.\n        api_key:\n            The API key used for authentication.\n        key_name:\n            The name of the API key used for authentication. If not provided, the first\n            API key in the environment variables will be used.\n        client:\n            The HTTP client instance used to make requests to the API. This could be an instance\n            of a library like `requests` or a custom client implementation.\n        verbose:\n            A boolean flag indicating whether to enable verbose output. When set to True,\n            additional debugging information or logs will be displayed.\n        logger:\n            A logger instance used for logging messages.\n        **kwargs:\n            Additional keyword arguments.\n    Examples:\n        ```python\n        from lumix.llm import OpenAI\n\n        base_url = \"https://open.bigmodel.cn/api/paas/v4\"\n        llm = OpenAI(model=\"glm-4-flash\", base_url=base_url, api_key=\"your_api_key\")\n        ```\n    \"\"\"\n    self.model = model\n    self.base_url = base_url\n    self.api_key = api_key\n    self.key_name = key_name\n    self.set_client(client)\n    self.logger = logger\n    self.verbose = verbose\n    self.kwargs = kwargs\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.completion","title":"completion","text":"<pre><code>completion(\n    prompt: Optional[str] = None,\n    messages: Optional[\n        Union[List[TypeMessage], List[Dict]]\n    ] = None,\n    stream: Optional[bool] = False,\n    tools: List[Dict] = None,\n    **kwargs\n) -&gt; Union[ChatCompletion | Stream[ChatCompletionChunk]]\n</code></pre> <p>Call OpenAI API to get a completion.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>Optional[str]</code> <p>The prompt to generate a completion.</p> <code>None</code> <code>messages</code> <code>Optional[Union[List[TypeMessage], List[Dict]]]</code> <p>The messages to generate a completion.</p> <code>None</code> <code>stream</code> <code>Optional[bool]</code> <p>Whether to stream the response or not.</p> <code>False</code> <code>tools</code> <code>List[Dict]</code> <p>The tools to generate a completion.</p> <code>None</code> <code>**kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <code>Union[ChatCompletion | Stream[ChatCompletionChunk]]</code> <p>Union[ChatCompletion | Stream[ChatCompletionChunk]]</p> <p>Examples:</p> <pre><code>completion = self.llm.completion(prompt=\"\u200b\u4f60\u597d\u200b\")\nprint(completion.choices[0].message.content)\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def completion(\n        self,\n        prompt: Optional[str] = None,\n        messages: Optional[Union[List[TypeMessage], List[Dict]]] = None,\n        stream: Optional[bool] = False,\n        tools: List[Dict] = None,\n        **kwargs,\n) -&gt; Union[ChatCompletion | Stream[ChatCompletionChunk]]:\n    \"\"\" Call OpenAI API to get a completion.\n\n    Args:\n        prompt: The prompt to generate a completion.\n        messages: The messages to generate a completion.\n        stream: Whether to stream the response or not.\n        tools: The tools to generate a completion.\n        **kwargs:\n\n    Returns:\n        Union[ChatCompletion | Stream[ChatCompletionChunk]]\n\n    Examples:\n        ```python\n        completion = self.llm.completion(prompt=\"\u200b\u4f60\u597d\u200b\")\n        print(completion.choices[0].message.content)\n        ```\n    \"\"\"\n    if prompt is not None:\n        messages = [Message(role=\"user\", content=prompt)]\n\n    if not isinstance(messages[0], dict):\n        messages = [msg.to_dict() for msg in messages]\n\n    self._logger(msg=f\"[User] {messages[-1].get(\"content\")}\\n\", color=\"blue\")\n    completion = self.client.chat.completions.create(\n        model=self.model, messages=messages, tools=tools, stream=stream, **kwargs)\n    if stream:\n        return self.sse(completion)\n    else:\n        return self.sync(completion)\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.sse","title":"sse","text":"<pre><code>sse(\n    completion: Stream[ChatCompletionChunk],\n) -&gt; Stream[ChatCompletionChunk]\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def sse(self, completion: Stream[ChatCompletionChunk]) -&gt; Stream[ChatCompletionChunk]:\n    \"\"\"\"\"\"\n    content = \"\"\n    for chunk in completion:\n        if chunk.choices[0].delta.content is not None:\n            content += chunk.choices[0].delta.content\n        yield chunk\n    self._logger(msg=f\"[Assistant] {content}\\n\", color=\"green\")\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.sync","title":"sync","text":"<pre><code>sync(completion: ChatCompletion) -&gt; ChatCompletion\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def sync(self, completion: ChatCompletion) -&gt; ChatCompletion:\n    \"\"\"\"\"\"\n    self._logger(msg=f\"[Assistant] {completion.choices[0].message.content}\\n\", color=\"green\")\n    return completion\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.structured_schema","title":"structured_schema","text":"<pre><code>structured_schema(schema: ModelMetaclass) -&gt; List[Dict]\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def structured_schema(self, schema: ModelMetaclass,) -&gt; List[Dict]:\n    \"\"\"\"\"\"\n    json_schema = schema.model_json_schema()\n    schema_tools = [{\n        'type': 'function',\n        'function': {\n            'name': json_schema.get(\"title\"),\n            'description': json_schema.get(\"description\"),\n            \"parameters\": {\n                \"type\": \"object\",\n                'properties': json_schema.get(\"properties\"),\n                'required': json_schema.get(\"required\")\n            },\n        }}]\n    return schema_tools\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.parse_dict","title":"parse_dict","text":"<pre><code>parse_dict(arguments: str) -&gt; Dict\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def parse_dict(self, arguments: str) -&gt; Dict:\n    \"\"\"\"\"\"\n    try:\n        return json.loads(arguments)\n    except Exception as e:\n        raise ValueError(f\"Invalid JSON: {e}\")\n</code></pre>"},{"location":"llm/#lumix.llm.completion.openai.OpenAI.structured_output","title":"structured_output","text":"<pre><code>structured_output(\n    schema: ModelMetaclass,\n    prompt: Optional[str] = None,\n    messages: Optional[\n        Union[List[TypeMessage], List[Dict]]\n    ] = None,\n    **kwargs\n) -&gt; Dict\n</code></pre> <p>\u200b\u7ed3\u6784\u5316\u200b\u8f93\u51fa\u200b</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelMetaclass</code> <p>\u200b\u8f93\u51fa\u200b\u7ed3\u6784\u200bScheme</p> required <code>prompt</code> <code>Optional[str]</code> <p>prompt</p> <code>None</code> <code>messages</code> <code>Optional[Union[List[TypeMessage], List[Dict]]]</code> <p>messages</p> <code>None</code> <code>**kwargs</code> <code>{}</code> <p>Returns:</p> Type Description <code>Dict</code> <p>\u200b\u7ed3\u6784\u5316\u200b\u6570\u636e\u200b</p> <p>Examples:</p> <pre><code>class Joke(BaseModel):\n    '''Joke to tell user.'''\n    setup: str = Field(description=\"The setup of the joke\")\n    punchline: str = Field(description=\"The punchline to the joke\")\n    rating: int = Field(description=\"How funny the joke is, from 1 to 10\")\n\ndata = self.llm.structured_output(schema=Joke, prompt=\"\u200b\u7ed9\u200b\u6211\u200b\u8bb2\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u7b11\u8bdd\u200b\")\npprint(data)\n</code></pre> Source code in <code>lumix\\llm\\completion\\openai.py</code> <pre><code>def structured_output(\n        self,\n        schema: ModelMetaclass,\n        prompt: Optional[str] = None,\n        messages: Optional[Union[List[TypeMessage], List[Dict]]] = None,\n        **kwargs\n) -&gt; Dict:\n    \"\"\"\u200b\u7ed3\u6784\u5316\u200b\u8f93\u51fa\u200b\n\n    Args:\n        schema: \u200b\u8f93\u51fa\u200b\u7ed3\u6784\u200bScheme\n        prompt: prompt\n        messages: messages\n        **kwargs:\n\n    Returns:\n        \u200b\u7ed3\u6784\u5316\u200b\u6570\u636e\u200b\n\n    Examples:\n        ```python\n        class Joke(BaseModel):\n            '''Joke to tell user.'''\n            setup: str = Field(description=\"The setup of the joke\")\n            punchline: str = Field(description=\"The punchline to the joke\")\n            rating: int = Field(description=\"How funny the joke is, from 1 to 10\")\n\n        data = self.llm.structured_output(schema=Joke, prompt=\"\u200b\u7ed9\u200b\u6211\u200b\u8bb2\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u7b11\u8bdd\u200b\")\n        pprint(data)\n        ```\n\n    \"\"\"\n    schema_tools = self.structured_schema(schema)\n    completion = self.completion(\n        prompt=prompt, messages=messages, stream=False, tools=schema_tools, **kwargs)\n    if completion.choices[0].message.tool_calls is not None:\n        return self.parse_dict(completion.choices[0].message.tool_calls[0].function.arguments)\n    else:\n        content = completion.choices[0].message.content\n        self.error(msg=f\"[{__class__.__name__}] No structured data found in the response: {content}\")\n        return {}\n</code></pre>"},{"location":"tools/","title":"Tools","text":"Baidu Search \u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200bOutput <pre><code>from lumix.agent.tools import BaiduSearch\n\nbaidu = BaiduSearch(verbose=True)\nweb_data = baidu.search(query=\"\u200b\u676d\u5dde\u200b\u5929\u6c14\u200b\", pages=1)\nprint(web_data)\n</code></pre> <pre><code>page_content='\\n\u3010\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b15\u200b\u5929\u200b_\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b15\u200b\u5929\u200b\u67e5\u8be2\u200b\u3011-\u200b\u4e2d\u56fd\u200b\u5929\u6c14\u200b\u7f51\u200b\u00d7\u200b\u676d\u5dde\u200b\\n8~15\u200b\u5929\u200b\u5929\u6c14\u9884\u62a5\u200b\uff0c\u200b\u662f\u200b\u96c6\u5408\u200b\u591a\u5bb6\u200b\u5168\u7403\u200b\u6570\u503c\u200b\u5929\u6c14\u9884\u62a5\u200b\u6a21\u5f0f\u200b\u5ba2\u89c2\u200b\u9884\u62a5\u200b\u4ea7\u54c1\u200b\u52a0\u5de5\u200b\u800c\u6210\u200b\uff0c\u200b\u672a\u7ecf\u200b\u9884\u62a5\u5458\u200b\u4e3b\u89c2\u200b\u8ba2\u6b63\u200b\uff0c\u200b\u53cd\u6620\u200b\u672a\u6765\u200b\u4e00\u6bb5\u65f6\u95f4\u200b\u5185\u200b\u5929\u6c14\u200b\u53d8\u5316\u8d8b\u52bf\u200b\uff0c\u200b\u5177\u6709\u200b\u4e00\u5b9a\u200b\u7684\u200b\u4e0d\u786e\u5b9a\u6027\u200b\uff0c\u200b\u4f9b\u200b\u516c\u4f17\u200b\u53c2\u8003\u200b\uff0c\u200b\u6b32\u77e5\u200b\u66f4\u52a0\u200b\u51c6\u786e\u200b\u7684\u200b\u5929\u6c14\u9884\u62a5\u200b\u9700\u200b\u968f\u65f6\u200b\u5173\u6ce8\u200b\u77ed\u671f\u200b\u5929\u6c14\u9884\u62a5\u200b\u548c\u200b\u6700\u65b0\u200b\u9884\u62a5\u200b\u4fe1\u606f\u200b\u66f4\u65b0\u200b\u3002\\n\u200b\u4eca\u5929\u200b\\n03/21\\n\u200b\u6674\u200b26/12\u2103\u200b\u897f\u5357\u98ce\u200b4-5\u200b\u7ea7\u200b\\n\u200b\u897f\u5357\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u516d\u200b\\n03/22\\n\u200b\u6674\u200b26/14\u2103\u200b\u897f\u5357\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u897f\u5357\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u65e5\u200b\\n03/23\\n\u200b\u591a\u4e91\u200b28/14\u2103\u200b\u897f\u5357\u98ce\u200b4-5\u200b\u7ea7\u200b\\n\u200b\u897f\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e00\u200b\\n03/24\\n\u200b\u6674\u200b29/14\u2103\u200b\u897f\u98ce\u200b4-5\u200b\u7ea7\u200b\\n\u200b\u897f\u5357\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e8c\u200b\\n03/25\\n\u200b\u591a\u4e91\u8f6c\u9634\u200b32/17\u2103\u200b\u897f\u5357\u98ce\u200b5-6\u200b\u7ea7\u200b\\n\u200b\u65e0\u200b\u6301\u7eed\u200b\u98ce\u5411\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e09\u200b\\n03/26\\n\u200b\u591a\u4e91\u200b\u8f6c\u200b\u96f7\u9635\u96e8\u200b34/21\u2103\u200b\u5357\u98ce\u200b5-6\u200b\u7ea7\u200b\\n\u200b\u897f\u98ce\u200b3-4\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u56db\u200b\\n03/27\\n\u200b\u5c0f\u5230\u4e2d\u96e8\u200b\u8f6c\u200b\u5c0f\u96e8\u200b27/8\u2103\u200b\u4e1c\u5317\u98ce\u200b6-7\u200b\u7ea7\u200b\\n\u200b\u897f\u5317\u98ce\u200b5-6\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e94\u200b\\n03/28\\n\u200b\u96e8\u200b\u8f6c\u9634\u200b10/3\u2103\u200b\u897f\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u897f\u5317\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u516d\u200b\\n03/29\\n\u200b\u9634\u8f6c\u96e8\u200b13/6\u2103\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u4e1c\u5357\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u65e5\u200b\\n03/30\\n\u200b\u6674\u8f6c\u9634\u200b17/7\u2103\u200b\u4e1c\u5317\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e00\u200b\\n03/31\\n\u200b\u9634\u200b20/8\u2103\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u4e1c\u5357\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e8c\u200b\\n04/01\\n\u200b\u9634\u8f6c\u96e8\u200b21/11\u2103\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u897f\u5317\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e09\u200b\\n04/02\\n\u200b\u96e8\u200b\u8f6c\u9634\u200b17/7\u2103\u200b\u4e1c\u5317\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u897f\u5357\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u56db\u200b\\n04/03\\n\u200b\u6674\u8f6c\u9634\u200b22/7\u2103\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\u5468\u4e94\u200b\\n04/04\\n\u200b\u9634\u8f6c\u591a\u4e91\u200b21/9\u2103\u200b\u4e1c\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u4e1c\u5357\u98ce\u200b&lt;3\u200b\u7ea7\u200b\\n\u200b\u8be6\u60c5\u200b\\n40\u200b\u5929\u200b\u9884\u62a5\u200b\\n\u200b\u6e29\u5ea6\u200b\u8d8b\u52bf\u200b\\n\u200b\u964d\u6c34\u200b\u8d8b\u52bf\u200b\u53f0\u98ce\u200b\u4e2d\u5fc3\u200b\u5229\u5947\u9a6c\u200b\\n\u200b\u5230\u8fbe\u200b\u65f6\u95f4\u200b\uff1a\\n2020-05-16\\n\u200b\u4e2d\u5fc3\u200b\u4f4d\u7f6e\u200b\uff1a\\n18.6N/120.1E\\n\u200b\u98ce\u901f\u200b\u98ce\u529b\u200b\uff1a\\n16\u200b\u7c73\u200b/\u200b\u79d2\u200b\\n\u200b\u4e2d\u5fc3\u200b\u6c14\u538b\u200b\uff1a\\n1000\uff08\u200b\u767e\u5e15\u200b\uff09\\n\u200b\u672a\u6765\u200b\u79fb\u901f\u200b\uff1a\\n17\u200b\u516c\u91cc\u200b/\u200b\u5c0f\u65f6\u200b\\n\u200b\u672a\u6765\u200b\u79fb\u9879\u200b\uff1a\\n\u200b\u5317\u200b\\n\u200b\u5929\u6c14\u200b\u96f7\u8fbe\u200b\\n\u200b\u6211\u200b\u7684\u200b\u5929\u7a7a\u200b\u7cbe\u5f69\u200b\u63a8\u8350\u200b\\n \u200b\u6625\u5929\u200b\u5927\u5e45\u200b\u63d0\u524d\u200b\uff01 \u200b\u5168\u56fd\u200b\u6625\u5b63\u200b\u82b1\u7c89\u200b\u9884\u62a5\u5730\u56fe\u200b\u6765\u200b\u4e86\u200b \u200b\u68a6\u5e7b\u200b\u552f\u7f8e\u200b\uff01\u200b\u5317\u4eac\u200b\u6843\u82b1\u200b\u6620\u200b\u65e5\u51fa\u200b \u200b\u6625\u5206\u200b\uff1a\u200b\u6625\u8272\u200b\u6b63\u4e2d\u200b\u5206\u200b \u200b\u5343\u82b1\u200b\u767e\u5349\u4e89\u200b\u660e\u5a9a\u200b \u200b\u6668\u5473\u200b\u65f6\u8282\u200b\u2014\u2014\u200b\u6625\u5206\u200b \u200b\u5982\u4f55\u200b\u7406\u89e3\u200b\u4eca\u5e74\u200b\u6c14\u8c61\u65e5\u200b\u7684\u200b\u4e3b\u9898\u200b\\n\u200b\u672a\u6765\u200b3\u200b\u5929\u200b\u516c\u62a5\u200b\u672a\u6765\u200b10\u200b\u5929\u200b\u516c\u62a5\u200b \u200b\u5929\u6c14\u200b  \u200b\u63a8\u8350\u200b\\n\u200b\u76f4\u64ad\u200b\\n\u200b\u56fe\u96c6\u200b\\n\u200b\u77ed\u200b\u89c6\u9891\u200b\\n\u200b\u751f\u6d3b\u200b\\n\\r\\n          \u200b\u6ca1\u6709\u200b\u66f4\u200b\u591a\u200b\u5566\u200b ~\\r\\n        \\n\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u6d4f\u89c8\u5668\u200b\u7684\u200b\u5206\u4eab\u200b\u529f\u80fd\u200b\u5206\u4eab\u200b\u9996\u9875\u200b \\n15\u200b\u5929\u200b \\n40\u200b\u5929\u200b \\n\u200b\u5730\u56fe\u200b \\n\u200b\u8d44\u8baf\u200b \\n\u200b\u66f4\u200b\u591a\u200b \\n\u200b\u6c14\u8c61\u200b\u6570\u636e\u200b\u6765\u6e90\u200b\uff1a\u200b\u4e2d\u592e\u6c14\u8c61\u53f0\u200b \\n\u200b\u9884\u62a5\u200b\u66f4\u65b0\u200b\u65f6\u95f4\u200b\uff1a\u200b\u6bcf\u65e5\u200b06\u300108\u300112\u300116\u300120\u200b\u65f6\u200b' metadata={'url': 'http://www.baidu.com/link?url=NLXajc-CXLQoFwlgK-nap57POT1dfLvR6YdwcV3qiPUSVmjiolmkOKptDLhVUpIFW4A48F-xmKWvJNGRaJEwAa', 'title': '\u3010\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b15\u200b\u5929\u200b_\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b15\u200b\u5929\u200b\u67e5\u8be2\u200b\u3011-\u200b\u4e2d\u56fd\u200b\u5929\u6c14\u200b\u7f51\u200b', 'abstract': '\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b,\u200b\u53ca\u65f6\u200b\u51c6\u786e\u200b\u53d1\u5e03\u200b\u4e2d\u592e\u6c14\u8c61\u53f0\u200b\u5929\u6c14\u200b\u4fe1\u606f\u200b,\u200b\u4fbf\u6377\u200b\u67e5\u8be2\u200b\u676d\u5dde\u200b\u4eca\u65e5\u200b\u5929\u6c14\u200b,\u200b\u676d\u5dde\u200b\u5468\u672b\u200b\u5929\u6c14\u200b,\u200b\u676d\u5dde\u200b\u4e00\u5468\u200b\u5929\u6c14\u9884\u62a5\u200b,\u200b\u676d\u5dde\u200b\u84dd\u5929\u200b\u9884\u62a5\u200b,\u200b\u676d\u5dde\u200b\u5929\u6c14\u9884\u62a5\u200b,\u200b\u676d\u5dde\u200b40\u200b\u65e5\u200b\u5929\u6c14\u9884\u62a5\u200b,\u200b\u8fd8\u200b\u63d0\u4f9b\u200b\u676d\u5dde\u200b\u7684\u200b\u751f\u6d3b\u200b\u6307\u6570\u200b\u3001\u200b\u5065\u200b...'}\n</code></pre>"},{"location":"blog/","title":"Blog","text":""}]}